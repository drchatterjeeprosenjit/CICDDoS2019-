{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-24T15:56:59.661141Z","iopub.execute_input":"2023-02-24T15:56:59.662512Z","iopub.status.idle":"2023-02-24T15:56:59.701752Z","shell.execute_reply.started":"2023-02-24T15:56:59.662403Z","shell.execute_reply":"2023-02-24T15:56:59.700334Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/undersampledrenn/Repeated_Edited_Nearest_Neighbors_Under-sampled_Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv('/kaggle/input/undersampledrenn/Repeated_Edited_Nearest_Neighbors_Under-sampled_Dataset.csv')\ndf = df[df['Label'] != 'BENIGN']","metadata":{"execution":{"iopub.status.busy":"2023-02-24T15:57:34.643501Z","iopub.execute_input":"2023-02-24T15:57:34.643941Z","iopub.status.idle":"2023-02-24T15:57:35.714551Z","shell.execute_reply.started":"2023-02-24T15:57:34.643908Z","shell.execute_reply":"2023-02-24T15:57:35.713651Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Bi-GRU","metadata":{}},{"cell_type":"markdown","source":"Average Training Accuracy: 0.9224836826324463\nAverage Training Loss: 0.1946489095687866\nAverage Testing Accuracy: 0.9221948742866516\nAverage Testing Loss: 0.19666993319988252","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import StratifiedKFold\n\n# Load the dataset\n#df = pd.read_csv('data.csv')\n\n# Split the data into features (X) and label (y)\nX = df.drop('Label', axis=1).values\ny = df['Label'].values\n\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# One-hot encode the label\n#y = tf.keras.utils.to_categorical(y)\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\ny = to_categorical(y)\n\n# Define the number of folds for stratified K-Fold\nn_splits = 5\n\n# Initialize Stratified K-Fold object\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# Define lists to store training and testing accuracies and losses for each fold\ntrain_acc_list = []\ntrain_loss_list = []\ntest_acc_list = []\ntest_loss_list = []\n\n# Loop through each fold and train and evaluate the model\nfor i, (train_index, test_index) in enumerate(skf.split(X, y.argmax(1))):\n    print(\"Running fold {}/{}...\".format(i+1, n_splits))\n    \n    # Split the data into training and testing sets for the current fold\n    train_X, test_X = X[train_index], X[test_index]\n    train_y, test_y = y[train_index], y[test_index]\n    \n    # Define the model\n    model = tf.keras.Sequential()\n\n    # Add the first GRU layer\n    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=64, return_sequences=True), input_shape=(features.shape[1], 1)))\n\n    # Add a dropout layer to prevent overfitting\n    model.add(tf.keras.layers.Dropout(0.5))\n\n    # Add the second GRU layer\n    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=32)))\n\n    # Add a dropout layer to prevent overfitting\n    model.add(tf.keras.layers.Dropout(0.5))\n\n    # Add a dense layer for the output\n    model.add(tf.keras.layers.Dense(units=train_y.shape[1], activation='softmax'))\n\n    # Compile the model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.summary()\n    # Train the model\n    history = model.fit(train_X, train_y, batch_size=32, epochs=5, validation_split=0.2)\n\n    # Evaluate the model on the training set\n    train_loss, train_accuracy = model.evaluate(train_X, train_y)\n\n    # Evaluate the model on the test set\n    test_loss, test_accuracy = model.evaluate(test_X, test_y)\n\n    # Append the training and testing accuracies and losses to their respective lists\n    train_acc_list.append(train_accuracy)\n    train_loss_list.append(train_loss)\n    test_acc_list.append(test_accuracy)\n    test_loss_list.append(test_loss)\n\n# Print the average training and testing accuracies and losses across all folds\nprint(\"Average Training Accuracy: {}\".format(np.mean(train_acc_list)))\nprint(\"Average Training Loss: {}\".format(np.mean(train_loss_list)))\nprint(\"Average Testing Accuracy: {}\".format(np.mean(test_acc_list)))\nprint(\"Average Testing Loss: {}\".format(np.mean(test_loss_list)))\n","metadata":{"execution":{"iopub.status.busy":"2023-02-24T08:01:31.365859Z","iopub.execute_input":"2023-02-24T08:01:31.366316Z","iopub.status.idle":"2023-02-24T09:37:27.687883Z","shell.execute_reply.started":"2023-02-24T08:01:31.366286Z","shell.execute_reply":"2023-02-24T09:37:27.687111Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Running fold 1/5...\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional (Bidirectiona  (None, 42, 128)          25728     \n l)                                                              \n                                                                 \n dropout (Dropout)           (None, 42, 128)           0         \n                                                                 \n bidirectional_1 (Bidirectio  (None, 64)               31104     \n nal)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 64)                0         \n                                                                 \n dense (Dense)               (None, 11)                715       \n                                                                 \n=================================================================\nTotal params: 57,547\nTrainable params: 57,547\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/5\n4000/4000 [==============================] - 205s 50ms/step - loss: 0.4318 - accuracy: 0.8489 - val_loss: 0.2686 - val_accuracy: 0.8996\nEpoch 2/5\n4000/4000 [==============================] - 187s 47ms/step - loss: 0.2541 - accuracy: 0.9042 - val_loss: 0.2058 - val_accuracy: 0.9174\nEpoch 3/5\n4000/4000 [==============================] - 200s 50ms/step - loss: 0.2819 - accuracy: 0.8954 - val_loss: 0.2166 - val_accuracy: 0.9131\nEpoch 4/5\n4000/4000 [==============================] - 214s 53ms/step - loss: 0.2413 - accuracy: 0.9079 - val_loss: 0.2036 - val_accuracy: 0.9167\nEpoch 5/5\n4000/4000 [==============================] - 212s 53ms/step - loss: 0.2282 - accuracy: 0.9120 - val_loss: 0.1885 - val_accuracy: 0.9267\n5000/5000 [==============================] - 62s 12ms/step - loss: 0.1865 - accuracy: 0.9267\n1250/1250 [==============================] - 15s 12ms/step - loss: 0.1805 - accuracy: 0.9295\nRunning fold 2/5...\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional_2 (Bidirectio  (None, 42, 128)          25728     \n nal)                                                            \n                                                                 \n dropout_2 (Dropout)         (None, 42, 128)           0         \n                                                                 \n bidirectional_3 (Bidirectio  (None, 64)               31104     \n nal)                                                            \n                                                                 \n dropout_3 (Dropout)         (None, 64)                0         \n                                                                 \n dense_1 (Dense)             (None, 11)                715       \n                                                                 \n=================================================================\nTotal params: 57,547\nTrainable params: 57,547\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/5\n4000/4000 [==============================] - 219s 53ms/step - loss: 0.4567 - accuracy: 0.8438 - val_loss: 0.2784 - val_accuracy: 0.9002\nEpoch 2/5\n4000/4000 [==============================] - 213s 53ms/step - loss: 0.2846 - accuracy: 0.8993 - val_loss: 0.2341 - val_accuracy: 0.9044\nEpoch 3/5\n4000/4000 [==============================] - 217s 54ms/step - loss: 0.2637 - accuracy: 0.9053 - val_loss: 0.2302 - val_accuracy: 0.9158\nEpoch 4/5\n4000/4000 [==============================] - 215s 54ms/step - loss: 0.2436 - accuracy: 0.9080 - val_loss: 0.2006 - val_accuracy: 0.9211\nEpoch 5/5\n4000/4000 [==============================] - 207s 52ms/step - loss: 0.2341 - accuracy: 0.9115 - val_loss: 0.2005 - val_accuracy: 0.9176\n5000/5000 [==============================] - 62s 12ms/step - loss: 0.1946 - accuracy: 0.9197\n1250/1250 [==============================] - 16s 13ms/step - loss: 0.1912 - accuracy: 0.9207\nRunning fold 3/5...\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional_4 (Bidirectio  (None, 42, 128)          25728     \n nal)                                                            \n                                                                 \n dropout_4 (Dropout)         (None, 42, 128)           0         \n                                                                 \n bidirectional_5 (Bidirectio  (None, 64)               31104     \n nal)                                                            \n                                                                 \n dropout_5 (Dropout)         (None, 64)                0         \n                                                                 \n dense_2 (Dense)             (None, 11)                715       \n                                                                 \n=================================================================\nTotal params: 57,547\nTrainable params: 57,547\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/5\n4000/4000 [==============================] - 225s 55ms/step - loss: 0.4355 - accuracy: 0.8518 - val_loss: 0.2452 - val_accuracy: 0.9103\nEpoch 2/5\n4000/4000 [==============================] - 210s 52ms/step - loss: 0.2729 - accuracy: 0.9034 - val_loss: 0.2100 - val_accuracy: 0.9175\nEpoch 3/5\n4000/4000 [==============================] - 217s 54ms/step - loss: 0.2451 - accuracy: 0.9090 - val_loss: 0.2146 - val_accuracy: 0.9195\nEpoch 4/5\n4000/4000 [==============================] - 215s 54ms/step - loss: 0.2298 - accuracy: 0.9151 - val_loss: 0.2022 - val_accuracy: 0.9200\nEpoch 5/5\n4000/4000 [==============================] - 213s 53ms/step - loss: 0.2238 - accuracy: 0.9156 - val_loss: 0.2000 - val_accuracy: 0.9205\n5000/5000 [==============================] - 61s 12ms/step - loss: 0.1962 - accuracy: 0.9230\n1250/1250 [==============================] - 15s 12ms/step - loss: 0.2063 - accuracy: 0.9188\nRunning fold 4/5...\nModel: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional_6 (Bidirectio  (None, 42, 128)          25728     \n nal)                                                            \n                                                                 \n dropout_6 (Dropout)         (None, 42, 128)           0         \n                                                                 \n bidirectional_7 (Bidirectio  (None, 64)               31104     \n nal)                                                            \n                                                                 \n dropout_7 (Dropout)         (None, 64)                0         \n                                                                 \n dense_3 (Dense)             (None, 11)                715       \n                                                                 \n=================================================================\nTotal params: 57,547\nTrainable params: 57,547\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/5\n4000/4000 [==============================] - 219s 53ms/step - loss: 0.4484 - accuracy: 0.8494 - val_loss: 0.2690 - val_accuracy: 0.9055\nEpoch 2/5\n4000/4000 [==============================] - 216s 54ms/step - loss: 0.2772 - accuracy: 0.9022 - val_loss: 0.2223 - val_accuracy: 0.9172\nEpoch 3/5\n4000/4000 [==============================] - 217s 54ms/step - loss: 0.2508 - accuracy: 0.9071 - val_loss: 0.2202 - val_accuracy: 0.9167\nEpoch 4/5\n4000/4000 [==============================] - 214s 54ms/step - loss: 0.2338 - accuracy: 0.9116 - val_loss: 0.1942 - val_accuracy: 0.9217\nEpoch 5/5\n4000/4000 [==============================] - 220s 55ms/step - loss: 0.2248 - accuracy: 0.9142 - val_loss: 0.2087 - val_accuracy: 0.9210\n5000/5000 [==============================] - 65s 13ms/step - loss: 0.2073 - accuracy: 0.9209\n1250/1250 [==============================] - 16s 12ms/step - loss: 0.2109 - accuracy: 0.9218\nRunning fold 5/5...\nModel: \"sequential_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional_8 (Bidirectio  (None, 42, 128)          25728     \n nal)                                                            \n                                                                 \n dropout_8 (Dropout)         (None, 42, 128)           0         \n                                                                 \n bidirectional_9 (Bidirectio  (None, 64)               31104     \n nal)                                                            \n                                                                 \n dropout_9 (Dropout)         (None, 64)                0         \n                                                                 \n dense_4 (Dense)             (None, 11)                715       \n                                                                 \n=================================================================\nTotal params: 57,547\nTrainable params: 57,547\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/5\n4000/4000 [==============================] - 229s 56ms/step - loss: 0.4681 - accuracy: 0.8387 - val_loss: 0.2623 - val_accuracy: 0.9047\nEpoch 2/5\n4000/4000 [==============================] - 220s 55ms/step - loss: 0.2771 - accuracy: 0.9032 - val_loss: 0.2420 - val_accuracy: 0.8990\nEpoch 3/5\n4000/4000 [==============================] - 217s 54ms/step - loss: 0.2505 - accuracy: 0.9086 - val_loss: 0.2109 - val_accuracy: 0.9222\nEpoch 4/5\n4000/4000 [==============================] - 217s 54ms/step - loss: 0.2320 - accuracy: 0.9113 - val_loss: 0.2010 - val_accuracy: 0.9225\nEpoch 5/5\n4000/4000 [==============================] - 212s 53ms/step - loss: 0.2237 - accuracy: 0.9135 - val_loss: 0.1895 - val_accuracy: 0.9208\n5000/5000 [==============================] - 61s 12ms/step - loss: 0.1887 - accuracy: 0.9221\n1250/1250 [==============================] - 16s 12ms/step - loss: 0.1944 - accuracy: 0.9202\nAverage Training Accuracy: 0.9224836826324463\nAverage Training Loss: 0.1946489095687866\nAverage Testing Accuracy: 0.9221948742866516\nAverage Testing Loss: 0.19666993319988252\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Bi-LSTM","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GRU\n\n# Load the dataset\n#df = pd.read_csv(\"data.csv\")\n\n# Split the dataset into features and labels\nX = df.drop(\"Label\", axis=1)\ny = df[\"Label\"]\n\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# Encode the labels\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\ny = to_categorical(y)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n\n\nmodel = Sequential()\nmodel.add(Dense(units=64, activation='relu', input_shape=(features.shape[1], 1)))\n#model.add(Reshape((features.shape[1], 1)))  # add a reshape layer to make the input 3D\nmodel.add(Bidirectional(LSTM(units=64, activation='tanh')))\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dense(units=16, activation='relu'))\nmodel.add(Dense(units=12, activation='relu'))\nmodel.add(Dense(units=y.shape[1], activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Fit the model to the training data\nhistory = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n\n# Evaluate the model on the test data\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-23T22:23:34.580672Z","iopub.execute_input":"2023-02-23T22:23:34.581476Z","iopub.status.idle":"2023-02-23T22:36:09.736238Z","shell.execute_reply.started":"2023-02-23T22:23:34.581427Z","shell.execute_reply":"2023-02-23T22:36:09.734524Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/5\n4000/4000 [==============================] - 153s 37ms/step - loss: 0.5723 - accuracy: 0.7789 - val_loss: 0.4117 - val_accuracy: 0.8453\nEpoch 2/5\n4000/4000 [==============================] - 147s 37ms/step - loss: 0.3895 - accuracy: 0.8539 - val_loss: 0.3608 - val_accuracy: 0.8541\nEpoch 3/5\n4000/4000 [==============================] - 147s 37ms/step - loss: 0.2656 - accuracy: 0.9017 - val_loss: 0.2515 - val_accuracy: 0.9034\nEpoch 4/5\n4000/4000 [==============================] - 147s 37ms/step - loss: 0.2224 - accuracy: 0.9166 - val_loss: 0.2365 - val_accuracy: 0.9204\nEpoch 5/5\n4000/4000 [==============================] - 147s 37ms/step - loss: 0.2146 - accuracy: 0.9189 - val_loss: 0.2014 - val_accuracy: 0.9250\n1250/1250 [==============================] - 13s 10ms/step - loss: 0.2058 - accuracy: 0.9235\nTest Loss: 0.20580387115478516\nTest Accuracy: 0.9234904646873474\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Bi-GRU","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout,BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\n\n\n\n# Extract the features and label\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# Encode the labels to numeric values\nencoder = LabelEncoder()\nlabels = encoder.fit_transform(labels)\nlabels = to_categorical(labels)\n\n# Define the number of folds\nn_splits = 5\n\n# Initialize lists to store results\ntrain_acc_list = []\ntrain_loss_list = []\ntest_acc_list = []\ntest_loss_list = []\nhistory_Array=[]\n\n\nmodel = tf.keras.Sequential()\n\n# Add the first GRU layer\nmodel.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=64, return_sequences=True), input_shape=(features.shape[1], 1)))\n\n# Add a dropout layer to prevent overfitting\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n# Add the second GRU layer\nmodel.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=32)))\n\n# Add a dropout layer to prevent overfitting\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n# Add a dense layer for the output\nmodel.add(tf.keras.layers.Dense(units=labels.shape[1], activation='softmax'))\n\n# Compile the model\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nmodel.summary()\n\n# Split the data into training and testing sets\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\nfor train_index, test_index in skf.split(features,labels.argmax(1)):\n    X_train, X_test = features[train_index], features[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]\n\n    # Reshape the data for LSTM\n    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n    # Train the model\n    history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n\n    history_Array.append(history)\n    \n    # Evaluate the model\n    train_loss, train_accuracy = model.evaluate(X_train, y_train)\n\n    # Evaluate the model on the test set\n    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n    \n    train_acc_list.append(train_accuracy)\n    train_loss_list.append(train_loss)\n    test_acc_list.append(test_accuracy)\n    test_loss_list.append(test_loss)\n\nprint(\"Average Training Accuracy: {}\".format(np.mean(train_acc_list)))\nprint(\"Average Training Loss: {}\".format(np.mean(train_loss_list)))\nprint(\"Average Testing Accuracy: {}\".format(np.mean(test_acc_list)))\nprint(\"Average Testing Loss: {}\".format(np.mean(test_loss_list)))","metadata":{"execution":{"iopub.status.busy":"2023-02-24T17:28:28.245660Z","iopub.execute_input":"2023-02-24T17:28:28.246077Z","iopub.status.idle":"2023-02-24T19:44:24.764123Z","shell.execute_reply.started":"2023-02-24T17:28:28.246045Z","shell.execute_reply":"2023-02-24T19:44:24.762823Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional_16 (Bidirecti  (None, 42, 128)          25728     \n onal)                                                           \n                                                                 \n dropout_15 (Dropout)        (None, 42, 128)           0         \n                                                                 \n bidirectional_17 (Bidirecti  (None, 64)               31104     \n onal)                                                           \n                                                                 \n dropout_16 (Dropout)        (None, 64)                0         \n                                                                 \n dense_6 (Dense)             (None, 11)                715       \n                                                                 \n=================================================================\nTotal params: 57,547\nTrainable params: 57,547\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/5\n5000/5000 [==============================] - 316s 62ms/step - loss: 0.3647 - accuracy: 0.8715 - val_loss: 0.2386 - val_accuracy: 0.9073\nEpoch 2/5\n5000/5000 [==============================] - 306s 61ms/step - loss: 0.2533 - accuracy: 0.9073 - val_loss: 0.2177 - val_accuracy: 0.9201\nEpoch 3/5\n5000/5000 [==============================] - 307s 61ms/step - loss: 0.2410 - accuracy: 0.9113 - val_loss: 0.2212 - val_accuracy: 0.9174\nEpoch 4/5\n5000/5000 [==============================] - 305s 61ms/step - loss: 0.2324 - accuracy: 0.9144 - val_loss: 0.2016 - val_accuracy: 0.9212\nEpoch 5/5\n5000/5000 [==============================] - 308s 62ms/step - loss: 0.2184 - accuracy: 0.9183 - val_loss: 0.1808 - val_accuracy: 0.9308\n5000/5000 [==============================] - 70s 14ms/step - loss: 0.1830 - accuracy: 0.9299\n1250/1250 [==============================] - 17s 14ms/step - loss: 0.1808 - accuracy: 0.9308\nEpoch 1/5\n5000/5000 [==============================] - 305s 61ms/step - loss: 0.1989 - accuracy: 0.9255 - val_loss: 0.1744 - val_accuracy: 0.9345\nEpoch 2/5\n5000/5000 [==============================] - 307s 61ms/step - loss: 0.1903 - accuracy: 0.9277 - val_loss: 0.1942 - val_accuracy: 0.9274\nEpoch 3/5\n5000/5000 [==============================] - 307s 61ms/step - loss: 0.1871 - accuracy: 0.9293 - val_loss: 0.1536 - val_accuracy: 0.9362\nEpoch 4/5\n5000/5000 [==============================] - 311s 62ms/step - loss: 0.1727 - accuracy: 0.9307 - val_loss: 0.1389 - val_accuracy: 0.9411\nEpoch 5/5\n5000/5000 [==============================] - 310s 62ms/step - loss: 0.1669 - accuracy: 0.9328 - val_loss: 0.1510 - val_accuracy: 0.9368\n5000/5000 [==============================] - 71s 14ms/step - loss: 0.1489 - accuracy: 0.9377\n1250/1250 [==============================] - 18s 14ms/step - loss: 0.1510 - accuracy: 0.9368\nEpoch 1/5\n5000/5000 [==============================] - 309s 62ms/step - loss: 0.1765 - accuracy: 0.9320 - val_loss: 0.1638 - val_accuracy: 0.9341\nEpoch 2/5\n5000/5000 [==============================] - 310s 62ms/step - loss: 0.1656 - accuracy: 0.9333 - val_loss: 0.1585 - val_accuracy: 0.9353\nEpoch 3/5\n5000/5000 [==============================] - 311s 62ms/step - loss: 0.1617 - accuracy: 0.9350 - val_loss: 0.1529 - val_accuracy: 0.9375\nEpoch 4/5\n5000/5000 [==============================] - 312s 62ms/step - loss: 0.1620 - accuracy: 0.9349 - val_loss: 0.1464 - val_accuracy: 0.9390\nEpoch 5/5\n5000/5000 [==============================] - 308s 62ms/step - loss: 0.1599 - accuracy: 0.9351 - val_loss: 0.1507 - val_accuracy: 0.9370\n5000/5000 [==============================] - 70s 14ms/step - loss: 0.1453 - accuracy: 0.9400\n1250/1250 [==============================] - 18s 14ms/step - loss: 0.1507 - accuracy: 0.9370\nEpoch 1/5\n5000/5000 [==============================] - 308s 62ms/step - loss: 0.1604 - accuracy: 0.9355 - val_loss: 0.1491 - val_accuracy: 0.9397\nEpoch 2/5\n5000/5000 [==============================] - 307s 61ms/step - loss: 0.1583 - accuracy: 0.9357 - val_loss: 0.1535 - val_accuracy: 0.9388\nEpoch 3/5\n5000/5000 [==============================] - 307s 61ms/step - loss: 0.1576 - accuracy: 0.9362 - val_loss: 0.1380 - val_accuracy: 0.9433\nEpoch 4/5\n5000/5000 [==============================] - 306s 61ms/step - loss: 0.1568 - accuracy: 0.9358 - val_loss: 0.1562 - val_accuracy: 0.9386\nEpoch 5/5\n5000/5000 [==============================] - 309s 62ms/step - loss: 0.1574 - accuracy: 0.9359 - val_loss: 0.1654 - val_accuracy: 0.9320\n5000/5000 [==============================] - 70s 14ms/step - loss: 0.1655 - accuracy: 0.9312\n1250/1250 [==============================] - 18s 14ms/step - loss: 0.1654 - accuracy: 0.9320\nEpoch 1/5\n5000/5000 [==============================] - 307s 61ms/step - loss: 0.1592 - accuracy: 0.9360 - val_loss: 0.1486 - val_accuracy: 0.9382\nEpoch 2/5\n5000/5000 [==============================] - 309s 62ms/step - loss: 0.1618 - accuracy: 0.9347 - val_loss: 0.1575 - val_accuracy: 0.9366\nEpoch 3/5\n5000/5000 [==============================] - 311s 62ms/step - loss: 0.1666 - accuracy: 0.9339 - val_loss: 0.1475 - val_accuracy: 0.9391\nEpoch 4/5\n5000/5000 [==============================] - 309s 62ms/step - loss: 0.1588 - accuracy: 0.9360 - val_loss: 0.1441 - val_accuracy: 0.9409\nEpoch 5/5\n5000/5000 [==============================] - 309s 62ms/step - loss: 0.1590 - accuracy: 0.9361 - val_loss: 0.1435 - val_accuracy: 0.9405\n5000/5000 [==============================] - 71s 14ms/step - loss: 0.1416 - accuracy: 0.9419\n1250/1250 [==============================] - 18s 14ms/step - loss: 0.1435 - accuracy: 0.9405\nAverage Training Accuracy: 0.9361216783523559\nAverage Training Loss: 0.15686407089233398\nAverage Testing Accuracy: 0.9354266405105591\nAverage Testing Loss: 0.1582488715648651\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN, Dropout\nfrom keras.utils import np_utils\n\n# Extract the features and label\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# Encode the labels to numeric values\nencoder = LabelEncoder()\nlabels = encoder.fit_transform(labels)\nlabels = np_utils.to_categorical(labels)\n\n# Define the number of folds for stratified K-fold cross-validation\nk_folds = 5\n\nmodel = Sequential()\nmodel.add(Bidirectional(GRU(units=64, return_sequences=True), input_shape=(features.shape[1], 1)))\nmodel.add(Dropout(0.3))\nmodel.add(Bidirectional(GRU(units=32)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units=labels.shape[1], activation='softmax'))\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n\ntrain_acc_list = []\ntrain_loss_list = []\ntest_acc_list = []\ntest_loss_list = []\n# Perform stratified K-fold cross-validation\nskf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\nfor i, (train_index, test_index) in enumerate(skf.split(features, labels.argmax(1))):\n    print(\"Fold\", i+1)\n\n    # Split the data into training and testing sets\n    X_train, X_test = features[train_index], features[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]\n\n    # Reshape the data for RNN\n    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n\n    # Evaluate the model\n    train_loss, train_accuracy = model.evaluate(X_train, y_train)\n\n    # Evaluate the model on the test set\n    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n    \n    train_acc_list.append(train_accuracy)\n    train_loss_list.append(train_loss)\n    test_acc_list.append(test_accuracy)\n    test_loss_list.append(test_loss)\n\nprint(\"Average Training Accuracy: {}\".format(np.mean(train_acc_list)))\nprint(\"Average Training Loss: {}\".format(np.mean(train_loss_list)))\nprint(\"Average Testing Accuracy: {}\".format(np.mean(test_acc_list)))\nprint(\"Average Testing Loss: {}\".format(np.mean(test_loss_list)))","metadata":{"execution":{"iopub.status.busy":"2023-02-24T00:24:14.541753Z","iopub.execute_input":"2023-02-24T00:24:14.542521Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential_32\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bidirectional_39 (Bidirecti  (None, 42, 128)          25728     \n onal)                                                           \n                                                                 \n dropout_23 (Dropout)        (None, 42, 128)           0         \n                                                                 \n bidirectional_40 (Bidirecti  (None, 64)               31104     \n onal)                                                           \n                                                                 \n dropout_24 (Dropout)        (None, 64)                0         \n                                                                 \n dense_65 (Dense)            (None, 11)                715       \n                                                                 \n=================================================================\nTotal params: 57,547\nTrainable params: 57,547\nNon-trainable params: 0\n_________________________________________________________________\nFold 1\nEpoch 1/5\n5000/5000 [==============================] - 333s 65ms/step - loss: 0.3559 - accuracy: 0.8737 - val_loss: 0.2196 - val_accuracy: 0.9153\nEpoch 2/5\n5000/5000 [==============================] - 320s 64ms/step - loss: 0.2326 - accuracy: 0.9114 - val_loss: 0.2063 - val_accuracy: 0.9204\nEpoch 3/5\n5000/5000 [==============================] - 319s 64ms/step - loss: 0.2188 - accuracy: 0.9164 - val_loss: 0.1972 - val_accuracy: 0.9229\nEpoch 4/5\n5000/5000 [==============================] - 320s 64ms/step - loss: 0.2106 - accuracy: 0.9185 - val_loss: 0.1782 - val_accuracy: 0.9317\nEpoch 5/5\n4708/5000 [===========================>..] - ETA: 17s - loss: 0.2017 - accuracy: 0.9205","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}