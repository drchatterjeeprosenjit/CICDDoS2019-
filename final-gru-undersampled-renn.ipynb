{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-23T19:17:42.358970Z","iopub.execute_input":"2023-02-23T19:17:42.359392Z","iopub.status.idle":"2023-02-23T19:17:42.375221Z","shell.execute_reply.started":"2023-02-23T19:17:42.359357Z","shell.execute_reply":"2023-02-23T19:17:42.374251Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"/kaggle/input/undersampledrenn/Repeated_Edited_Nearest_Neighbors_Under-sampled_Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv('/kaggle/input/undersampledrenn/Repeated_Edited_Nearest_Neighbors_Under-sampled_Dataset.csv')\ndf = df[df['Label'] != 'BENIGN']","metadata":{"execution":{"iopub.status.busy":"2023-02-23T19:17:46.504923Z","iopub.execute_input":"2023-02-23T19:17:46.506185Z","iopub.status.idle":"2023-02-23T19:17:47.546285Z","shell.execute_reply.started":"2023-02-23T19:17:46.506132Z","shell.execute_reply":"2023-02-23T19:17:47.545211Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Simple GRU With Startified K-Fold","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GRU, Dropout\nfrom keras.utils import np_utils\n\n# Extract the features and label\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# Encode the labels to numeric values\nencoder = LabelEncoder()\nlabels = encoder.fit_transform(labels)\nlabels = np_utils.to_categorical(labels)\n\n# Define the number of folds for stratified K-fold cross-validation\nk_folds = 5\n\n# Define the GRU model\nmodel = Sequential()\nmodel.add(GRU(units=32,  input_shape=(features.shape[1], 1), return_sequences=True))\nmodel.add(GRU(units=32))\nmodel.add(Dense(units=labels.shape[1], activation='softmax'))\n\n# Compile the model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\ntrain_acc_list = []\ntrain_loss_list = []\ntest_acc_list = []\ntest_loss_list = []\n# Perform stratified K-fold cross-validation\nskf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\nfor i, (train_index, test_index) in enumerate(skf.split(features, labels.argmax(1))):\n    print(\"Fold\", i+1)\n\n    # Split the data into training and testing sets\n    X_train, X_test = features[train_index], features[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]\n\n    # Reshape the data for RNN\n    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n\n    # Evaluate the model\n    train_loss, train_accuracy = model.evaluate(X_train, y_train)\n\n    # Evaluate the model on the test set\n    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n    \n    train_acc_list.append(train_accuracy)\n    train_loss_list.append(train_loss)\n    test_acc_list.append(test_accuracy)\n    test_loss_list.append(test_loss)\n\nprint(\"Average Training Accuracy: {}\".format(np.mean(train_acc_list)))\nprint(\"Average Training Loss: {}\".format(np.mean(train_loss_list)))\nprint(\"Average Testing Accuracy: {}\".format(np.mean(test_acc_list)))\nprint(\"Average Testing Loss: {}\".format(np.mean(test_loss_list)))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T23:22:39.534011Z","iopub.execute_input":"2023-02-23T23:22:39.534610Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fold 1\nEpoch 1/5\n5000/5000 [==============================] - 220s 43ms/step - loss: 0.4120 - accuracy: 0.8552 - val_loss: 0.2551 - val_accuracy: 0.9071\nEpoch 2/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.2464 - accuracy: 0.9084 - val_loss: 0.2270 - val_accuracy: 0.9138\nEpoch 3/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.2188 - accuracy: 0.9141 - val_loss: 0.2051 - val_accuracy: 0.9187\nEpoch 4/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.2094 - accuracy: 0.9166 - val_loss: 0.1949 - val_accuracy: 0.9212\nEpoch 5/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.2053 - accuracy: 0.9187 - val_loss: 0.2138 - val_accuracy: 0.9179\n5000/5000 [==============================] - 49s 10ms/step - loss: 0.2179 - accuracy: 0.9156\n1250/1250 [==============================] - 12s 10ms/step - loss: 0.2138 - accuracy: 0.9179\nFold 2\nEpoch 1/5\n5000/5000 [==============================] - 216s 43ms/step - loss: 0.1983 - accuracy: 0.9206 - val_loss: 0.1880 - val_accuracy: 0.9254\nEpoch 2/5\n5000/5000 [==============================] - 216s 43ms/step - loss: 0.1974 - accuracy: 0.9216 - val_loss: 0.1949 - val_accuracy: 0.9219\nEpoch 3/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1997 - accuracy: 0.9208 - val_loss: 0.1855 - val_accuracy: 0.9267\nEpoch 4/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.1912 - accuracy: 0.9238 - val_loss: 0.1794 - val_accuracy: 0.9269\nEpoch 5/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1843 - accuracy: 0.9248 - val_loss: 0.2239 - val_accuracy: 0.9126\n5000/5000 [==============================] - 50s 10ms/step - loss: 0.2221 - accuracy: 0.9121\n1250/1250 [==============================] - 12s 10ms/step - loss: 0.2239 - accuracy: 0.9126\nFold 3\nEpoch 1/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.1680 - accuracy: 0.9318 - val_loss: 0.1780 - val_accuracy: 0.9273\nEpoch 2/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1592 - accuracy: 0.9336 - val_loss: 0.1883 - val_accuracy: 0.9245\nEpoch 3/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1580 - accuracy: 0.9347 - val_loss: 0.1558 - val_accuracy: 0.9342\nEpoch 4/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1570 - accuracy: 0.9350 - val_loss: 0.1656 - val_accuracy: 0.9293\nEpoch 5/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1562 - accuracy: 0.9358 - val_loss: 0.1572 - val_accuracy: 0.9329\n5000/5000 [==============================] - 49s 10ms/step - loss: 0.1510 - accuracy: 0.9349\n1250/1250 [==============================] - 12s 10ms/step - loss: 0.1572 - accuracy: 0.9329\nFold 4\nEpoch 1/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.1554 - accuracy: 0.9349 - val_loss: 0.1498 - val_accuracy: 0.9375\nEpoch 2/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1525 - accuracy: 0.9356 - val_loss: 0.1479 - val_accuracy: 0.9392\nEpoch 3/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1541 - accuracy: 0.9349 - val_loss: 0.1460 - val_accuracy: 0.9396\nEpoch 4/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1582 - accuracy: 0.9346 - val_loss: 0.1451 - val_accuracy: 0.9389\nEpoch 5/5\n5000/5000 [==============================] - 214s 43ms/step - loss: 0.1514 - accuracy: 0.9363 - val_loss: 0.1608 - val_accuracy: 0.9361\n5000/5000 [==============================] - 49s 10ms/step - loss: 0.1577 - accuracy: 0.9361\n1250/1250 [==============================] - 12s 10ms/step - loss: 0.1608 - accuracy: 0.9361\nFold 5\nEpoch 1/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.1499 - accuracy: 0.9368 - val_loss: 0.1486 - val_accuracy: 0.9378\nEpoch 2/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.1483 - accuracy: 0.9371 - val_loss: 0.1529 - val_accuracy: 0.9338\nEpoch 3/5\n5000/5000 [==============================] - 215s 43ms/step - loss: 0.1481 - accuracy: 0.9372 - val_loss: 0.1402 - val_accuracy: 0.9389\nEpoch 4/5\n2595/5000 [==============>...............] - ETA: 1:38 - loss: 0.1466 - accuracy: 0.9365","output_type":"stream"}]},{"cell_type":"markdown","source":"# SIMPLE GRU","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GRU\n\n# Load the dataset\n#df = pd.read_csv(\"data.csv\")\n\n# Split the dataset into features and labels\nX = df.drop(\"Label\", axis=1)\ny = df[\"Label\"]\n\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# Encode the labels\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\ny = to_categorical(y)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(GRU(units=32,  input_shape=(features.shape[1], 1), return_sequences=True))\nmodel.add(GRU(units=32))\nmodel.add(Dense(units=y.shape[1], activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Fit the model to the training data\nhistory = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n\n# Evaluate the model on the test data\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Optuna","metadata":{}},{"cell_type":"markdown","source":"# This Structure is Following from a Paper","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GRU, Dropout\nfrom keras.utils import np_utils\n\n# Extract the features and label\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# Encode the labels to numeric values\nencoder = LabelEncoder()\nlabels = encoder.fit_transform(labels)\nlabels = np_utils.to_categorical(labels)\n\n# Define the number of folds for stratified K-fold cross-validation\nk_folds = 5\n\n# Define the GRU model\nmodel = Sequential()\nmodel.add(GRU(units=32, input_shape=(features.shape[1], 1), return_sequences=True))\nmodel.add(GRU(units=32))\nmodel.add(LayerNormalization())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(units=labels.shape[1], activation='softmax'))\n\n# Compile the model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\ntrain_acc_list = []\ntrain_loss_list = []\ntest_acc_list = []\ntest_loss_list = []\n# Perform stratified K-fold cross-validation\nskf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\nfor i, (train_index, test_index) in enumerate(skf.split(features, labels.argmax(1))):\n    print(\"Fold\", i+1)\n\n    # Split the data into training and testing sets\n    X_train, X_test = features[train_index], features[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]\n\n    # Reshape the data for RNN\n    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n\n    # Evaluate the model\n    train_loss, train_accuracy = model.evaluate(X_train, y_train)\n\n    # Evaluate the model on the test set\n    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n    \n    train_acc_list.append(train_accuracy)\n    train_loss_list.append(train_loss)\n    test_acc_list.append(test_accuracy)\n    test_loss_list.append(test_loss)\n\nprint(\"Average Training Accuracy: {}\".format(np.mean(train_acc_list)))\nprint(\"Average Training Loss: {}\".format(np.mean(train_loss_list)))\nprint(\"Average Testing Accuracy: {}\".format(np.mean(test_acc_list)))\nprint(\"Average Testing Loss: {}\".format(np.mean(test_loss_list)))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T19:27:02.036783Z","iopub.execute_input":"2023-02-23T19:27:02.037231Z","iopub.status.idle":"2023-02-23T21:05:09.264866Z","shell.execute_reply.started":"2023-02-23T19:27:02.037196Z","shell.execute_reply":"2023-02-23T21:05:09.263553Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Fold 1\nEpoch 1/5\n5000/5000 [==============================] - 275s 45ms/step - loss: 0.4453 - accuracy: 0.8340 - val_loss: 0.2684 - val_accuracy: 0.8984\nEpoch 2/5\n5000/5000 [==============================] - 222s 44ms/step - loss: 0.2497 - accuracy: 0.9031 - val_loss: 0.2239 - val_accuracy: 0.9145\nEpoch 3/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.2177 - accuracy: 0.9130 - val_loss: 0.2393 - val_accuracy: 0.9069\nEpoch 4/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1890 - accuracy: 0.9222 - val_loss: 0.1638 - val_accuracy: 0.9304\nEpoch 5/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1664 - accuracy: 0.9321 - val_loss: 0.1466 - val_accuracy: 0.9417\n5000/5000 [==============================] - 51s 10ms/step - loss: 0.1495 - accuracy: 0.9395\n1250/1250 [==============================] - 13s 10ms/step - loss: 0.1466 - accuracy: 0.9417\nFold 2\nEpoch 1/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1570 - accuracy: 0.9348 - val_loss: 0.1427 - val_accuracy: 0.9410\nEpoch 2/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1520 - accuracy: 0.9367 - val_loss: 0.1462 - val_accuracy: 0.9384\nEpoch 3/5\n5000/5000 [==============================] - 219s 44ms/step - loss: 0.1469 - accuracy: 0.9386 - val_loss: 0.1528 - val_accuracy: 0.9361\nEpoch 4/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1458 - accuracy: 0.9388 - val_loss: 0.1429 - val_accuracy: 0.9407\nEpoch 5/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1436 - accuracy: 0.9402 - val_loss: 0.1453 - val_accuracy: 0.9392\n5000/5000 [==============================] - 50s 10ms/step - loss: 0.1454 - accuracy: 0.9398\n1250/1250 [==============================] - 13s 10ms/step - loss: 0.1453 - accuracy: 0.9392\nFold 3\nEpoch 1/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1439 - accuracy: 0.9401 - val_loss: 0.1448 - val_accuracy: 0.9377\nEpoch 2/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1406 - accuracy: 0.9419 - val_loss: 0.1319 - val_accuracy: 0.9441\nEpoch 3/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.1395 - accuracy: 0.9417 - val_loss: 0.1652 - val_accuracy: 0.9290\nEpoch 4/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.1392 - accuracy: 0.9413 - val_loss: 0.1347 - val_accuracy: 0.9429\nEpoch 5/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1362 - accuracy: 0.9425 - val_loss: 0.1400 - val_accuracy: 0.9404\n5000/5000 [==============================] - 52s 10ms/step - loss: 0.1346 - accuracy: 0.9424\n1250/1250 [==============================] - 13s 10ms/step - loss: 0.1400 - accuracy: 0.9404\nFold 4\nEpoch 1/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1350 - accuracy: 0.9432 - val_loss: 0.1281 - val_accuracy: 0.9467\nEpoch 2/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.1344 - accuracy: 0.9433 - val_loss: 0.1348 - val_accuracy: 0.9426\nEpoch 3/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1339 - accuracy: 0.9434 - val_loss: 0.1256 - val_accuracy: 0.9468\nEpoch 4/5\n5000/5000 [==============================] - 220s 44ms/step - loss: 0.1333 - accuracy: 0.9433 - val_loss: 0.1347 - val_accuracy: 0.9411\nEpoch 5/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.1322 - accuracy: 0.9441 - val_loss: 0.1456 - val_accuracy: 0.9386\n5000/5000 [==============================] - 51s 10ms/step - loss: 0.1424 - accuracy: 0.9386\n1250/1250 [==============================] - 13s 10ms/step - loss: 0.1456 - accuracy: 0.9386\nFold 5\nEpoch 1/5\n5000/5000 [==============================] - 222s 44ms/step - loss: 0.1318 - accuracy: 0.9438 - val_loss: 0.1274 - val_accuracy: 0.9461\nEpoch 2/5\n5000/5000 [==============================] - 222s 44ms/step - loss: 0.1305 - accuracy: 0.9449 - val_loss: 0.1321 - val_accuracy: 0.9440\nEpoch 3/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.1308 - accuracy: 0.9447 - val_loss: 0.1269 - val_accuracy: 0.9458\nEpoch 4/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.1289 - accuracy: 0.9452 - val_loss: 0.1246 - val_accuracy: 0.9470\nEpoch 5/5\n5000/5000 [==============================] - 221s 44ms/step - loss: 0.1298 - accuracy: 0.9452 - val_loss: 0.1363 - val_accuracy: 0.9411\n5000/5000 [==============================] - 51s 10ms/step - loss: 0.1311 - accuracy: 0.9441\n1250/1250 [==============================] - 13s 10ms/step - loss: 0.1363 - accuracy: 0.9411\nAverage Training Accuracy: 0.9408960580825806\nAverage Training Loss: 0.14059441685676574\nAverage Testing Accuracy: 0.9402322411537171\nAverage Testing Loss: 0.14277182817459105\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}