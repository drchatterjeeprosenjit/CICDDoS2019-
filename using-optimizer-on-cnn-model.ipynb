{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-19T20:12:37.265844Z","iopub.execute_input":"2023-02-19T20:12:37.266229Z","iopub.status.idle":"2023-02-19T20:12:37.277008Z","shell.execute_reply.started":"2023-02-19T20:12:37.266197Z","shell.execute_reply":"2023-02-19T20:12:37.275701Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/undersampleddatausingrepeatedenn/undersampled_using_repeated_enn.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('/kaggle/input/undersampleddatausingrepeatedenn/undersampled_using_repeated_enn.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T20:13:08.659684Z","iopub.execute_input":"2023-02-19T20:13:08.660085Z","iopub.status.idle":"2023-02-19T20:13:11.193276Z","shell.execute_reply.started":"2023-02-19T20:13:08.660051Z","shell.execute_reply":"2023-02-19T20:13:11.192381Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\nfrom keras.utils import np_utils\n\n# Extract the features and label\nfeatures = df.drop(\"Label\", axis=1).values\nlabels = df[\"Label\"].values\n\n# Encode the labels to numeric values\nencoder = LabelEncoder()\nlabels = encoder.fit_transform(labels)\nlabels = np_utils.to_categorical(labels)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\n# Reshape the data for CNN\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n# Define the CNN model\nmodel = Sequential()\nmodel.add(Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(Conv1D(64, 3, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(labels.shape[1], activation='softmax'))\n\n# Compile the model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n\n# Evaluate the model\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T20:19:45.201990Z","iopub.execute_input":"2023-02-19T20:19:45.202367Z","iopub.status.idle":"2023-02-19T20:22:43.842602Z","shell.execute_reply.started":"2023-02-19T20:19:45.202336Z","shell.execute_reply":"2023-02-19T20:22:43.841537Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/5\n2775/2775 [==============================] - 36s 13ms/step - loss: 425038.9688 - accuracy: 0.6575 - val_loss: 97.0508 - val_accuracy: 0.8286\nEpoch 2/5\n2775/2775 [==============================] - 35s 13ms/step - loss: 112.5811 - accuracy: 0.8723 - val_loss: 39.4158 - val_accuracy: 0.8834\nEpoch 3/5\n2775/2775 [==============================] - 35s 12ms/step - loss: 750.6102 - accuracy: 0.8683 - val_loss: 0.9041 - val_accuracy: 0.8687\nEpoch 4/5\n2775/2775 [==============================] - 34s 12ms/step - loss: 0.5656 - accuracy: 0.8824 - val_loss: 0.4246 - val_accuracy: 0.8932\nEpoch 5/5\n2775/2775 [==============================] - 34s 12ms/step - loss: 0.3966 - accuracy: 0.8911 - val_loss: 0.4691 - val_accuracy: 0.8924\nTest loss: 0.46912312507629395\nTest accuracy: 0.8924428224563599\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Use Optuna to Optimize Hyper Parameter CNN**","metadata":{}},{"cell_type":"code","source":"!pip install optuna","metadata":{"execution":{"iopub.status.busy":"2023-02-19T20:38:36.131285Z","iopub.execute_input":"2023-02-19T20:38:36.131666Z","iopub.status.idle":"2023-02-19T20:38:47.866176Z","shell.execute_reply.started":"2023-02-19T20:38:36.131637Z","shell.execute_reply":"2023-02-19T20:38:47.864887Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.7/site-packages (3.1.0)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (1.4.41)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from optuna) (6.7.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (1.9.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from optuna) (4.64.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (23.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from optuna) (1.21.6)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from optuna) (6.0)\nRequirement already satisfied: cmaes>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from optuna) (0.9.1)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (6.0.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (5.10.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (4.1.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\nfrom keras.utils import np_utils\n\n# Define the objective function for Optuna to optimize\ndef objective(trial):\n    # Define the hyperparameters to optimize\n    filters1 = trial.suggest_int(\"filters1\", 32, 128)\n    filters2 = trial.suggest_int(\"filters2\", 32, 128)\n    window1 = trial.suggest_int(\"window1\", 2, 5)\n    window2 = trial.suggest_int(\"window2\", 2, 5)\n    dense_units = trial.suggest_int(\"dense_units\", 64, 256)\n    \n    # Extract the features and label\n    features = df.drop(\"Label\", axis=1).values\n    labels = df[\"Label\"].values\n\n    # Encode the labels to numeric values\n    encoder = LabelEncoder()\n    labels = encoder.fit_transform(labels)\n    labels = np_utils.to_categorical(labels)\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\n    # Reshape the data for CNN\n    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n\n    # Define the CNN model\n    model = Sequential()\n    model.add(Conv1D(filters=filters1, kernel_size=window1, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n    model.add(Conv1D(filters=filters2, kernel_size=window2, activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dense(dense_units, activation='relu'))\n    model.add(Dense(labels.shape[1], activation='softmax'))\n\n    # Compile the model\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=0)\n\n    # Evaluate the model\n    score = model.evaluate(X_test, y_test, verbose=0)\n    return score[0]\n\n# Define the study and optimize the objective function\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=50)\n\n# Print the best hyperparameters and the best loss\nprint(\"Best hyperparameters: \", study.best_params)\nprint(\"Best loss: \", study.best_value)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T20:38:51.930757Z","iopub.execute_input":"2023-02-19T20:38:51.931174Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-02-19 20:38:51,944]\u001b[0m A new study created in memory with name: no-name-882de31c-4efc-443f-a3fe-2b1182f15061\u001b[0m\n\u001b[32m[I 2023-02-19 20:43:13,665]\u001b[0m Trial 0 finished with value: 0.2756122350692749 and parameters: {'filters1': 117, 'filters2': 46, 'window1': 2, 'window2': 5, 'dense_units': 71}. Best is trial 0 with value: 0.2756122350692749.\u001b[0m\n\u001b[32m[I 2023-02-19 20:46:37,434]\u001b[0m Trial 1 finished with value: 0.6039955019950867 and parameters: {'filters1': 36, 'filters2': 91, 'window1': 4, 'window2': 5, 'dense_units': 202}. Best is trial 0 with value: 0.2756122350692749.\u001b[0m\n\u001b[32m[I 2023-02-19 20:50:04,507]\u001b[0m Trial 2 finished with value: 0.26765820384025574 and parameters: {'filters1': 61, 'filters2': 62, 'window1': 4, 'window2': 5, 'dense_units': 169}. Best is trial 2 with value: 0.26765820384025574.\u001b[0m\n\u001b[32m[I 2023-02-19 20:53:36,175]\u001b[0m Trial 3 finished with value: 0.2662080228328705 and parameters: {'filters1': 92, 'filters2': 62, 'window1': 2, 'window2': 3, 'dense_units': 235}. Best is trial 3 with value: 0.2662080228328705.\u001b[0m\n\u001b[32m[I 2023-02-19 20:58:01,903]\u001b[0m Trial 4 finished with value: 2.2554469108581543 and parameters: {'filters1': 78, 'filters2': 125, 'window1': 4, 'window2': 4, 'dense_units': 81}. Best is trial 3 with value: 0.2662080228328705.\u001b[0m\n\u001b[32m[I 2023-02-19 21:01:44,551]\u001b[0m Trial 5 finished with value: 0.45139551162719727 and parameters: {'filters1': 60, 'filters2': 89, 'window1': 5, 'window2': 4, 'dense_units': 219}. Best is trial 3 with value: 0.2662080228328705.\u001b[0m\n\u001b[32m[I 2023-02-19 21:06:12,633]\u001b[0m Trial 6 finished with value: 0.28463295102119446 and parameters: {'filters1': 70, 'filters2': 94, 'window1': 3, 'window2': 4, 'dense_units': 134}. Best is trial 3 with value: 0.2662080228328705.\u001b[0m\n\u001b[32m[I 2023-02-19 21:11:11,363]\u001b[0m Trial 7 finished with value: 0.666110098361969 and parameters: {'filters1': 82, 'filters2': 104, 'window1': 5, 'window2': 5, 'dense_units': 130}. Best is trial 3 with value: 0.2662080228328705.\u001b[0m\n\u001b[32m[I 2023-02-19 21:14:48,883]\u001b[0m Trial 8 finished with value: 0.40686434507369995 and parameters: {'filters1': 68, 'filters2': 84, 'window1': 5, 'window2': 4, 'dense_units': 94}. Best is trial 3 with value: 0.2662080228328705.\u001b[0m\n\u001b[32m[I 2023-02-19 21:17:31,475]\u001b[0m Trial 9 finished with value: 23.710491180419922 and parameters: {'filters1': 56, 'filters2': 68, 'window1': 4, 'window2': 3, 'dense_units': 64}. Best is trial 3 with value: 0.2662080228328705.\u001b[0m\n\u001b[32m[I 2023-02-19 21:20:19,000]\u001b[0m Trial 10 finished with value: 0.21919456124305725 and parameters: {'filters1': 108, 'filters2': 33, 'window1': 2, 'window2': 2, 'dense_units': 247}. Best is trial 10 with value: 0.21919456124305725.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}